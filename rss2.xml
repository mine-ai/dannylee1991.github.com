<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>studyAI</title>
    <link>http://studyai.site/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Sun, 24 Sep 2017 01:39:15 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>【原创】不用一句深度学习术语来讲解神经网络运作原理</title>
      <link>http://studyai.site/2017/09/24/%E4%B8%8D%E7%94%A8%E4%B8%80%E5%8F%A5%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%AF%E8%AF%AD%E6%9D%A5%E8%AE%B2%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%90%E4%BD%9C%E5%8E%9F%E7%90%86/</link>
      <guid>http://studyai.site/2017/09/24/%E4%B8%8D%E7%94%A8%E4%B8%80%E5%8F%A5%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%AF%E8%AF%AD%E6%9D%A5%E8%AE%B2%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%90%E4%BD%9C%E5%8E%9F%E7%90%86/</guid>
      <pubDate>Sat, 23 Sep 2017 17:11:00 GMT</pubDate>
      <description>
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;原创文章，转载请注明出处&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;神经网络-多层级组织架构的公司&quot;&gt;&lt;a href=&quot;#神经网络-多层级组织架构的公司&quot; class=&quot;headerlink&quot; title=&quot;神经网络==多层级组织架构的公
        
      
      </description>
      
      <content:encoded><![CDATA[<blockquote><p>原创文章，转载请注明出处</p></blockquote><h2 id="神经网络-多层级组织架构的公司"><a href="#神经网络-多层级组织架构的公司" class="headerlink" title="神经网络==多层级组织架构的公司"></a>神经网络==多层级组织架构的公司</h2><p>假设有一家公司，这家公司的组织架构是下面这种多层级的结构：</p><p><img src="/img/17_09_24/001.png" alt=""></p><p>公司每天接待一批固定数量的用户，这些用户会将自己的数据告诉给公司，公司做的事情就是通过每个用户上报的数据来推测当前用户群体整体所表现出来的状态。</p><p><img src="/img/17_09_24/002.png" alt=""></p><p>公司中直接与用户打交道的只有基层业务员，小部门经理只与基层业务员打交道，大部门经理只与小部门经理打交道…依此类推，层层递进，直到CEO这一层。</p><p>并且其中每一个基层业务员会了解每个用户的数据，每个小部门经理也会了解每个基层业务员输出的情况，…，依次类推，直到CEO。而CEO需要了解的是每个副总经理输出的情况。</p><p>公司拿到一批用户的数据之后，首先交给基层业务员。每个基层业务员看到了每个用户的数据之后，都会针对每一个用户出一份数据分析报表（由于每个人的观点不同，所以每个人得出的报表都不一样）；然后每个小部门经理也会分别去看每个业务员输出的报表，然后自己再输出一个针对每一个基层业务员输出的数据的分析报表；同样，每个大部门经理也会去这样看每个小部门经理输出的报表，然后出一份针对每一个小部门经理输出的数据的分析报表；…；以此类推，最终CEO会输出一个针对每一个副总经理输出的数据的分析报表，这份报表里就是公司当前对用户状态的理解。</p><p><img src="/img/17_09_24/003.png" alt=""></p><p>那么公司对用户状态把握到底准确不准确呢？这需要一个衡量标准。</p><p>所以我们需要对公司进行考核，将一部分已知状态的用户数据给到公司，看公司是否能足够准确的预测出这个状态。换句话说，就是CEO最后输出的这份报表，与用户的真实状态之间相差有多大。</p><p><img src="/img/17_09_24/004.png" alt=""></p><p>如果CEO发现自己的预测和真实情况偏差很大，它会带头思考自己工作上到底哪里做的不够好导致最终的判断失误，以及自己需要如何调整状态才能使公司表现更好，然后号召副总经理反思并调整状态。副总经理反思调整之后，会号召他的直属下级部门反思并调整状态。以此类推，直到基层业务员。但其实每个人都不能完全保证调整的状态是否可靠，所以大家就比较保守的<strong>稍微调整一下</strong>自己的工作状态。</p><p>当全公司员工调整状态完成之后，在面对新的用户数据，看是否能更加准确的预测用户群体的状态。如果发现上面的调整确实有效，那么继续按照上面的方式调整：由CEO再次依次号召下面的员工来调整工作状态，调整之后继续面对新的用户。重复执行上面的操作若干次之后，直到公司的预测效果趋于稳定为止（和真实状态对比之后，差值基本不再变化了）。</p><p><img src="/img/17_09_24/005.png" alt=""></p><p>此时的公司就相当于经历了若干次碰壁，并且若干次全员反思、调整状态之后，各个员工都成为了精兵强将了，对于用户数据的把握也更加准确了。</p><p>现在，我们回头看看公司接待的客户。假设公司每天共接待1024位用户，每个用户都举着一个纯色的卡片，卡片颜色是灰度值介于0到255之间的某个颜色。</p><p><img src="/img/17_09_24/006.png" alt=""></p><p>将这些用户按顺序排在32×32的平面上，每个用户占一格。当他们将手里的纯色卡片高举并拼凑起来之后，我们会看到一个写有数字的图片。</p><p><img src="/img/17_09_24/007.png" alt=""></p><p>公司做的事情就是每天接待这1024个用户，他们会告诉公司自己手里卡片的灰度值，但不会告诉公司卡片拼起来的图片是什么，然后公司经过层层分析来得出当前所有用户卡片拼起来的图像是什么。</p><p>这就是一个用户识别手写数字的DNN模型的形象比喻。</p><hr><h3 id="几个问题的思考"><a href="#几个问题的思考" class="headerlink" title="几个问题的思考"></a>几个问题的思考</h3><h4 id="公司员工数量一定的情况下，组织架构是越扁平越好，还是层级越多越好？"><a href="#公司员工数量一定的情况下，组织架构是越扁平越好，还是层级越多越好？" class="headerlink" title="公司员工数量一定的情况下，组织架构是越扁平越好，还是层级越多越好？"></a>公司员工数量一定的情况下，组织架构是越扁平越好，还是层级越多越好？</h4><p>扁平化的架构带来的好处是快速直接触达用户，但最终的准确率会比较低；多层级的架构带来的好处是更合理的分工，但会带来沟通和管理上的开销和数据损失。</p><p>所以如何设置公司层级是一门学问。</p><h4 id="每个员工是如何生成报表的？"><a href="#每个员工是如何生成报表的？" class="headerlink" title="每个员工是如何生成报表的？"></a>每个员工是如何生成报表的？</h4><p>每个员工根据自己对每个数据的重要程度的看法，计算出自己对每个数据的看法。然后在经过一层加工处理之后输出报表。</p><h4 id="公司招聘员工的时候，应该招聘类似的人群，还是招聘差异化的人群？"><a href="#公司招聘员工的时候，应该招聘类似的人群，还是招聘差异化的人群？" class="headerlink" title="公司招聘员工的时候，应该招聘类似的人群，还是招聘差异化的人群？"></a>公司招聘员工的时候，应该招聘类似的人群，还是招聘差异化的人群？</h4><p>应该招聘差异化大的人群，这样每个人能够产生对数据的不同看法。如果公司大部分人背景相似，那么他们对待同一类问题，产生的看法也都相似，没有多样化的观点，也容易导致公司做出错误判断。</p><hr><h3 id="带入术语"><a href="#带入术语" class="headerlink" title="带入术语"></a>带入术语</h3><ul><li>神经网络 -&gt; 多层级结构的公司</li><li>神经网络架构 -&gt; 公司组织架构</li><li>神经元 -&gt; 每一位员工</li><li>损失函数/代价函数 -&gt; 公司最终预测结果 - 真实结果</li><li>输入数据源 -&gt; 每天所有用户的卡片灰度值向量</li><li>输入数据标签值 -&gt; 所有用户卡片拼凑起来的数字图像的真实数值</li><li>反向传播 -&gt; 由CEO牵头，依次带领全公司员工反思</li><li>正向传递 -&gt; 带入每天的用户数据，层层递进，输出最终预测结果</li><li>激活函数 -&gt; 每个员工对数据的加工</li><li>参数 -&gt; 每个员工对数据的主观看法</li><li>随机初始化参数 -&gt; 招聘差异化人群</li><li>输入层 -&gt; 用户层</li><li>隐藏层 -&gt; 除了CEO之外的所有员工层级</li><li>输出层 -&gt; CEO层</li><li>梯度下降 -&gt; 公司朝着缩小预测错误程度的方向全员反思调整状态的过程</li><li>学习率 -&gt; 每次调整状态的程度α</li><li>训练/学习 -&gt; 带入大量已知状态的用户数据来根据公司的预测结果调整全员状态的过程</li></ul><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>神经网络是一个灵活的结构，当带入图片像素值以及图片标签数据时，它训练的就是一个图片识别模型；当带入的数据是邮件特征数据，以及邮件是否为垃圾邮件的类别数据时，它可能就是一个垃圾邮件识别模型。</p><p>这里的类比并不严谨，准确的定义还需要参考标准定义。不过通过形象化的类比，可以使我们对神经网络建立起系统化的认知。</p>]]></content:encoded>
      
      <comments>http://studyai.site/2017/09/24/%E4%B8%8D%E7%94%A8%E4%B8%80%E5%8F%A5%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%AF%E8%AF%AD%E6%9D%A5%E8%AE%B2%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%90%E4%BD%9C%E5%8E%9F%E7%90%86/#disqus_thread</comments>
    </item>
    
    <item>
      <title>【Tensorflow r1.0 程序员指南】-变量：创建，初始化，保存和加载</title>
      <link>http://studyai.site/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91-%E5%8F%98%E9%87%8F%EF%BC%9A%E5%88%9B%E5%BB%BA%EF%BC%8C%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%8C%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/</link>
      <guid>http://studyai.site/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91-%E5%8F%98%E9%87%8F%EF%BC%9A%E5%88%9B%E5%BB%BA%EF%BC%8C%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%8C%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/</guid>
      <pubDate>Tue, 08 Aug 2017 14:08:58 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;当你训练一个模型时，您可以使用&lt;a href=&quot;https://www.tensorflow.org/api_guides/python/state_ops&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;variables&lt;/a&gt;来保存和更新参数。vari
        
      
      </description>
      
      <content:encoded><![CDATA[<p>当你训练一个模型时，您可以使用<a href="https://www.tensorflow.org/api_guides/python/state_ops" target="_blank" rel="external">variables</a>来保存和更新参数。variables是包含张量的内存缓冲区。variables必须明确地被初始化，并在训练期间和之后将其保存到磁盘。在之后您可以恢复保存的值，以运行或分析模型。</p><p>本文档引用了以下TensorFlow类。请参阅其参考手册的链接，了解其API的完整说明：</p><ul><li><a href="https://www.tensorflow.org/api_docs/python/tf/Variable" target="_blank" rel="external">tf.Variable</a></li><li><a href="https://www.tensorflow.org/api_docs/python/tf/train/Saver" target="_blank" rel="external">tf.train.Saver</a></li></ul><h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><p>当您创建一个<a href="https://www.tensorflow.org/api_guides/python/state_ops" target="_blank" rel="external">Variable</a>时，您将<code>Tensor</code>作为其初始值传递给<code>Variable()</code>构造函数。TensorFlow提供了一个操作的集合，它们产生经常用于从<a href="https://www.tensorflow.org/api_guides/python/constant_op" target="_blank" rel="external">常量或随机初始化的</a>张量。</p><p>请注意，所有这些操作都需要您指定张量的形状。该形状自动变为变量的形状。变量通常具有固定的形状，但是TensorFlow提供了重新变换变量的高级机制。</p>]]></content:encoded>
      
      <comments>http://studyai.site/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91-%E5%8F%98%E9%87%8F%EF%BC%9A%E5%88%9B%E5%BB%BA%EF%BC%8C%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%8C%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/#disqus_thread</comments>
    </item>
    
    <item>
      <title>【Tensorflow r1.0 程序员指南】</title>
      <link>http://studyai.site/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91/</link>
      <guid>http://studyai.site/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91/</guid>
      <pubDate>Tue, 08 Aug 2017 13:12:58 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;程序员指南&quot;&gt;&lt;a href=&quot;#程序员指南&quot; class=&quot;headerlink&quot; title=&quot;程序员指南&quot;&gt;&lt;/a&gt;程序员指南&lt;/h2&gt;&lt;p&gt;这一部分文档将深入到TensorFlow的代码细节。这一节由以下几个指南开始，每一个指南都介绍了TensorFlow
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="程序员指南"><a href="#程序员指南" class="headerlink" title="程序员指南"></a>程序员指南</h2><p>这一部分文档将深入到TensorFlow的代码细节。这一节由以下几个指南开始，每一个指南都介绍了TensorFlow的一个特定的方面：</p><ul><li><a href="">变量：创建，初始化，保存和加载</a>，详细介绍了TensorFlow变量的机制。</li><li><a href="">张量等级，形状和类型</a>，这部分说明了Tensor等级（维数），形状（每个维的大小）和数据类型。</li><li><a href="">共享变量</a>，这部分解释了在构建复杂模型时如何共享和管理大量变量。</li><li><a href="">线程和队列</a>，这部分说明了TensorFlow的富队列系统。</li><li><a href="">读取数据</a>，其中记录了将数据导入TensorFlow程序的三种不同机制。</li></ul><p>以下指南适用于对复杂模型的多天训练：</p><ul><li><a href="">监督：多天训练的训练助手</a>，介绍如何在长时间的训练过程中妥善处理系统崩溃。</li></ul><p>TensorFlow提供了一个名叫<code>tfdbg</code>的调试器，它的文档见下面两个指南：</p><ul><li><p><a href="">TensorFlow Debugger（tfdbg）命令行界面教程：MNIST</a>，它将引导您使用<code>tfdbg</code>在低级TensorFlow API中编写的应用程序。</p></li><li><p><a href="">如何在tf.contrib.learn中使用TensorFlow Debugger（tfdbg）</a>，它演示了如何在Estimators API中使用<code>tfdbg</code>。</p></li></ul><p><code>MetaGraph</code>由计算图及其相关元数据组成。<code>MetaGraph</code>包含持续训练，执行评估或在先前训练过的图表上运行推断所需的信息。以下指南是<code>MetaGraph</code>对象的详细说明：</p><ul><li><a href="">MetaGraph的导入和导出</a></li></ul><p><code>SavedModel</code>是Tensorflow模型的通用序列化格式。TensorFlow提供SavedModel CLI（命令行界面）作为在<code>SavedModel</code>中检查和执行<code>MetaGraph</code>的工具。以下指南中记录了详细的用法和示例：</p><ul><li><a href="">SavedModel CLI（命令行界面）</a></li></ul><p>要了解TensorFlow版本控制方案，请参阅以下两个指南：</p><ul><li><a href="">TensorFlow版本语义</a>，这说明了TensorFlow的版本控制术语和兼容性规则。</li><li><a href="">TensorFlow数据版本控制：GraphDefs和检查点</a>，这解释了TensorFlow如何将版本信息添加到计算图形和检查点，以便支持跨版本的兼容性。</li></ul><p>结束本部分有关TensorFlow编程的常见问题：</p><ul><li><a href="">常见问题</a></li></ul>]]></content:encoded>
      
      <comments>http://studyai.site/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91/#disqus_thread</comments>
    </item>
    
    <item>
      <title>【斯坦福cs231n】2-2线性分类</title>
      <link>http://studyai.site/2017/08/03/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-2%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/</link>
      <guid>http://studyai.site/2017/08/03/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-2%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/</guid>
      <pubDate>Thu, 03 Aug 2017 15:39:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;线性分类&quot;&gt;&lt;a href=&quot;#线性分类&quot; class=&quot;headerlink&quot; title=&quot;线性分类&quot;&gt;&lt;/a&gt;线性分类&lt;/h2&gt;&lt;p&gt;在最后一节中，我们介绍了图像分类的问题，这是从一组固定的类别向一个图像分配单个标签的任务。更多的，我们描述了通过将图像与来自
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="线性分类"><a href="#线性分类" class="headerlink" title="线性分类"></a>线性分类</h2><p>在最后一节中，我们介绍了图像分类的问题，这是从一组固定的类别向一个图像分配单个标签的任务。更多的，我们描述了通过将图像与来自训练集的（注释）图像进行比较来标记图像的k-最近邻（kNN）分类器。我们看到，kNN有一些缺点：</p><ul><li>分类器必须记住所有的训练数据并将其存储，以便将来与测试数据进行比较。这在空间上是低效的，因为数据集的大小可能很容易达到千兆字节。</li><li>分类器执行对单个测试样本进行预测的操作是昂贵的，因为它需要与所有训练图像进行比较。</li></ul><p><strong>概述.</strong>我们现在要开发更强大的图像分类方法，我们最终将自然地扩展到整个神经网络和卷积神经网络。该方法将有两个主要部分：一个<strong>得分函数</strong>，这个函数是原始数据到预测分类的得分的映射；以及<strong>损失函数</strong>，这个函数衡量了预测得分与真实结果之间的差值。然后，我们将图像分类问题作为一个最小化相对于得分函数的损失函数的优化问题。</p><h2 id="从图像到标签分数的参数化映射"><a href="#从图像到标签分数的参数化映射" class="headerlink" title="从图像到标签分数的参数化映射"></a>从图像到标签分数的参数化映射</h2><p>该方法的第一个组成部分是定义将图像的像素值映射到每个类的置信度得分的分数函数。我们将以具体的例子来介绍这种方法。像以前一样，我们假设一个图像训练数据集$x_i \in R^D$，每个图像都有一个相关的标签$y_i$。在这里，我们定义$i = 1 \dots N$，并且$y_i \in { 1 \dots K }$。也就是说我们拥有$N$个样本（每个样本的维数都是$D$）和$K$个不同的类别。例如，在CIFAR-10中，我们有一个训练集，它有$N=50,000$张图片，其中每张图片都是$D=32 x 32 x 3 = 3072$像素，并且由于一共有10个不同的类别（狗，猫，车等等），所以$K=10$。我们现在将定义将原始图像像素映射到类分数的分数函数：$f: R^D \mapsto R^K$。</p><p><strong>线性分类器.</strong>在这个模块中，我们可以从最简单的一个线性映射函数开始：</p><p>$$<br>f(x_i, W, b) =  W x_i + b<br>$$</p><p>在上述等式中，我们假设图像$x_i$将其所有像素平坦化形状为[D x 1]的列向量。矩阵$W$(大小是[K x D])，向量$b$（大小是[K x 1]）是函数的<strong>参数</strong>。在CIFAR-10中，$x_i$包含第i张图中的所有像素，并且展开成为单列的尺寸为[3072 x 1]的向量，$W$尺寸是[10 x 3072]，$b$的尺寸是[10 x 1]，所以这个函数每次有3072个参数输入（原始像素值），并且有10个参数输出（10个类别的得分）。参数$W$通常被称为<strong>权重(weights)</strong>，$b$被称为<strong>偏差向量(bias vector)</strong>，因为它会在不与实际输入数据$x_i$发生交互的情况下，影响输出分数值。但是，您经常会听到人们用<em>权重</em>或者<em>参数</em>这样的术语来描述这一概念。</p><p>有一些注意事项：</p><ul><li>首先，注意$Wx_i$的矩阵乘法部分，正在对10个独立的分类器进行并行的评估，其中$W$的每一行分别是一个类别的分类器。</li><li>同时也要注意，给定的输入数据$(x_i, y_i)$是不可变的，但是我们可以控制调节参数$W,b$。我们的目标是通过设置这些参数，使得最终分类器计算出来的得分与整个训练集中的真实标签数据相匹配。我们将详细介绍如何做到这一点，但从直觉上来说，我们希望被正确分类的分数是高于错误分类的分数的。</li><li>这种方法的一个优点是训练数据被用于学习参数$W,b$，但一旦学习完成，我们就可以忽略训练数据集，并且只保留学习得到的参数值即可。这是因为一个新的测试图像可以通过调用这个方法来基于已经算出的分数进行分类。</li><li>最后，注意测试图像分类涉及到一个单个的矩阵乘法和加法操作，这明显比将测试图像与所有训练图像进行比较更快。</li></ul><blockquote><p>卷积：卷积神经访问将图像像素映射到如上所示的分数，但映射(f)更复杂，并且包含更多的参数。</p></blockquote><h2 id="解释线性分类器"><a href="#解释线性分类器" class="headerlink" title="解释线性分类器"></a>解释线性分类器</h2><p>请注意，线性分类器将其分类计算为其所有3个颜色通道中的所有像素值的加权和。分类结果取决于我们为这些权重设置什么具体值，该函数具有在图像中某些位置的某些颜色的喜欢或者不喜欢的能力（取决于每个权重的符号）。例如，你可以想象，如果图像的边缘部分有很多的蓝色（这部分可能是水），那么这张图片是“船”的类别的可能性更大。你可能希望“船”分类器在其蓝色通道有着正权重（蓝色增加“船”类别的分值），而在红色/绿色通道中有着负权重（红色/绿色的存在降低“船”类别的分值）。</p><hr><p><img src="/img/17_08_03/001.jpg" alt=""></p><blockquote><p>一个将图像到分类得分的映射例子。为了方便可视化，我们假设图像只有4个像素（4个单色像素，这里我们不考虑彩色通道），我们有三个类别（红色（猫），绿色（狗），蓝色（船））。（说明：这里的颜色简单的表示了3个类别，但与RGB通道无关。）我们将图像像素拉伸成一列，并执行矩阵乘法以得到每个类的分数。请注意，这里给定的权重W不是很好：我们传入一张猫的图片，通过这个权重计算得到的对应的猫的得分很低。实际上，这套权重对应得到的得分似乎在说明它看到的是一条狗。</p></blockquote><hr><p><strong>将图像比作高维点.</strong>由于图像被拉伸成高维列向量，我们可以将每个图像解释为该空间中的单个点（例如，CIFAR-10中的每个图像是32×32×3像素的3072维空间中的点）。类似地，整个数据集是一个（被标记的）的点集合。</p><p>由于我们将每一个类的分数定义为所有图像像素的加权和，所以每个类对应的分数在这个空间上是一个线性函数。我们无法想象3072维空间的样子，但如果我们想象将所有的维度都挤压到两个维度时，那么我们就可以试着去可视化分类器正在做的事情：</p><p><img src="/img/17_08_03/002.jpeg" alt=""></p><blockquote><p>图像空间中，每个图像都是单个点，并且有三个分类器被可视化。使用汽车分类器（红色）的示例，红色线显示空间中为汽车分类得分为0的所有点。红色箭头表示的是分数增加方向，所以红线右侧的所有点都是正（线性增加）得分，并且左边的所有点都是负（线性递减）得分。</p></blockquote><hr><p>正如我们上面所见到的，权重矩阵$W$的每一行都对应一个类别的分类器。这些数字的几何解释是：当我们更改$W$的其中一行时，像素控件中的相应行将沿不同方向旋转。另一方面，偏置量$b$允许我们的分类器转换行。特别要注意的是，没有偏置量时，插入$x_i=0$时，不管权值为何值，最终得到的分数总是0，所以所有分类器的线条都被迫穿过原点。</p><p><strong>将线性分类器解释为模板匹配.</strong>对于权重$W$的另外一种解释是每一行都对应一个类的模板（有时也称为原型）。然后，通过使用<em>内积</em>（或<em>点积</em>）逐个比较每个模板与图像，以获得最适合的图像，从而获得每个类的分数。当我们执行内积操作的时候，线性分类器正在进行模板匹配，其中模板是通过学习得到的。另一种看待这个问题的方法是我们依然在执行最邻近操作，但是，相比与成千上万的训练图像进行比较，我们这里只是使用单个图像进行比较（尽管我们会学习这张图，但它不一定是训练集中的图像），并且我们使用（负）内积作为距离而不是L1或L2距离。</p><p><img src="/img/17_08_03/003.jpg" alt=""></p><blockquote><p>CIFAR-10学习结束时得到的权重示例。注意，例如，船模板包含大量蓝色像素。因此，一旦与其内部在海洋上的船舶图像相匹配，该模板就会得到高分。</p></blockquote><hr><p>此外，请注意，马模板似乎包含一个双头马，这是由于数据集中有左右两匹马造成的。线性分类器将这两种模式的马在数据中合并成一个模板。类似地，汽车分类器似乎已经将多种模式合并成了单个模板，其必须从各方面以及所有颜色识别汽车。特别地，这个模板最终表现是红色的，这暗示着CIFAR-10数据集中红色的车占汽车类别的大部分。线性分类器太弱，无法正确识别不同颜色的汽车，但正如我们将看到的，神经网络将允许我们执行此任务。神经网络能够通过其隐藏层来开发出可以检测特定汽车类型的中间神经元（例如面向左方的绿色汽车，面向前方的蓝色汽车等），并且下一层的神经元可以通过各个车辆检测器的加权和来将它们组合成更准确的车辆分数。</p><p><strong>偏置技巧.</strong>在继续下面的内容之前，我们将介绍一个通用的简化技巧，将两个参数$W,b$表示为一个参数。回想一下，我们将得分函数定义为：</p><p>$$<br>f(x_i, W, b) =  W x_i + b<br>$$</p><p>对两个参数分别跟踪考虑（偏置$b$和重量$W$）是有点麻烦的。一个常用的技巧是将两组参数组合成一个单一的矩阵，我们通过将向量$x_i$扩展一个额外的维度，其值为常数1–一个默认的偏置维度。使用额外的维度，新的分数函数将简化为单个矩阵乘法：</p><p>$$<br>f(x_i, W) =  W x_i<br>$$</p><p>在我们的CIFAR-10例子中，$x_i$现在的维度由[3072 x 1]变为了[3073 x 1]-（额外的维度的值为常数1），$W$现在由[10 x 3072]变为了[10 x 3073]。现在$W$矩阵额外增加的那一列对应了偏置量$b$。下面是一个帮助我们理解的例子：</p><p><img src="/img/17_08_03/004.jpeg" alt=""></p><blockquote><p>上图介绍了调整偏置量的小技巧。执行一次矩阵乘法，然后将结果与偏置量（左侧）相加，等效于对所有输入向量添加常数为1的偏置维度，并将权重矩阵向右扩展一列偏置列（右侧）。因此，如果我们通过将其附加到所有向量来预处理我们的数据，我们只需要学习一个权重矩阵，而不是保存权重和偏差两个矩阵。</p></blockquote><hr><p><strong>图像数据预处理.</strong>请注意，在上面的例子中，我们使用了原始像素值（范围从[0 … 255]）。在机器学习中，对输入数据进行归一化操作是非常常见的做法（在图像识别的例子中，每一个像素被认为是一个特征）。特别地，通过减去每个特征的平均值来<strong>确定数据的中心值</strong>是很重要的。在图像识别的例子中，这对应于计算训练图像上的平均图像，并从每个图像中减去它，以获得像素范围大约在[-127 … 127]的图像。进一步的常用预处理是缩放每个输入特征，使其值范围落在[-1,1]的区间内。其中，均值为0是更为重要的步骤，但我们理解动态梯度下降之后我们才可以解释这一原因。</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>在上一节中，我们定义了由一组权重$W$参数化的像素到得分的映射函数。此外，我们并没有控制数据$(x_i,y_i)$(这些数据是外部给到并不可改变的)，但我们控制了权重，并且我们希望通过设置这些权值来预测分类得分，从而达到与真实标签相符合的效果。</p><p>例如，回到我们前面的那个将猫的图片分类到“猫”，“狗”和“船”的例子中，我们可以看到那个例子中的特定定权值并不是非常好：我们传入了一张画有猫的图片，但对于猫的分类得分，相比对于其他类别（狗的得分是437.9，船的得分是61.95）却非常低(-96.8)。我们可以通过<strong>损失函数</strong>（有时也被称为<strong>代价函数</strong>或<strong>目标</strong>）来衡量我们的分类器有多差。直观的说，如果我们在训练集上分类的效果不好，那么损失值将会很高，反之，则会很低。</p><h3 id="多类SVM损失函数"><a href="#多类SVM损失函数" class="headerlink" title="多类SVM损失函数"></a>多类SVM损失函数</h3><p>有几种方法来定义损失函数的细节。作为第一个例子，我们将首先开发一种称为<strong>多类别支持向量机（SVM）</strong>损失函数的常用损失函数。SVM损失函数被设置为使得SVM“想要”每个图像的正确类别具有比不正确类别高得多的固定的余量$\Delta$。请注意，如上所述，有时有助于拟合损失函数：SVM“想要”某种结果，意味着结果将产生较低的损失（这是好的）。</p><p>我们来看一下更准确的描述。回想一下我们给出的第i个样本的图像$x_i$以及其标识对应类别的标签$y_i$。得分函数$f(x_i, W)$接受像素值并且计算出得分向量，我们简称为$s$(分数的简写)。例如，第j个类别的得分是函数结果的第j个元素：$s_j = f(x_i, W)_j$。然后将第i个例子的多类SVM损失函数表示如下形式：</p><p>$$<br>L_i = \sum_{j\neq y_i} \max(0, s_j - s_{y_i} + \Delta)<br>$$</p><p><strong>例如.</strong>让我们通过一个例子来了解他是如何工作的。假设我们有三个类，可以得到$s = [13, -7, 11]$，第一个类别对应的是true（即$y_i = 0$）。并且假设$\Delta$（一个我们稍后会介绍到的超参数）的值是10。根据上面的针对错误分类得分的求和表达式（$j \neq y_i$），我们可以得到下面的结果：</p><p>$$<br>L_i = \max(0, -7 - 13 + 10) + \max(0, 11 - 13 + 10)<br>$$</p><p>你可以看到第一部分的结果是0，因为[-7 - 13 + 10]得出的是一个负数，然后通过函数$max(0,-)$将其阈值化为0。我们得到的损失值为0，因为正确分类的得分（13）比不正确分类的得分（-7）相距大于10。事实上，他们的距离是20，这个值是远大于10的，但SVM只关心差值最多在10以内；任何高于此间距的额外差值被取最大值操作控制在了0的位置上。第二部分关于[11 - 13 + 10]的计算结果是8。也就是说，即使正确的分类比不正确的分类（13&gt;11）有更高的分数，但并没有超过10的间隔值。其差值仅仅为2，所以其损失值为8（即，差额要高出多少才能超过间隔值）。总而言之，SVM损失函数希望被正确分类的到$y_i$的得分要比不正确分类的得分至少要大$\Delta$。如果不是这样，我们就会累计损失值。</p><p>请注意，在这个特定的模块中我们正在使用线性评分函数($f(x_i; W) =  W x_i$)，所以我们也可以以等效的方式重写损失函数：</p><p>$$<br>L_i = \sum_{j\neq y_i} \max(0, w_j^T x_i - w_{y_i}^T x_i + \Delta)<br>$$</p><p>这里的$w_j$是权重矩阵$W$的第j行转化为列的形式。然而，在更复杂的评分函数$f$的形式中，不一定是这样的。</p><p>在我们完成本节之前，我们将提到的最后一个术语是值域为0的$max(0,-)$函数，我们通常称为<strong>转折点损失(hinge loss)</strong>。有时候您会听到有关人们使用形式为$max(0,-)^2$的对违规惩罚更强烈（二次而不是线性）的平方转折点损失SVM（或L2-SVM）。无平方计算的是更为标准的版本，但在某些数据集中，平方转折点损失可以工作的更好。这一点可以在交叉验证期间确定。</p><blockquote><p>损失函数量化了我们对训练集的预测结果的不满意程度。</p></blockquote><hr><p><img src="/img/17_08_03/005.jpg" alt=""></p><blockquote><p>多类别支持向量机“想要”正确分类的分数比其他分数至少多出delta的大小。如果任何类别在红色区域内（或者更高）都有分数，那么就会有累计的损失。否则损失值为0。</p></blockquote><hr><p><strong>正则化.</strong>上面提到的损失函数有一个bug。假设我们有一个数据集，并且有一组用于正确分类每个样本的参数$W$（例如，所有的分数都是满足所有的边距值，并且对于所有的i都有$L_i = 0$）。问题是这套$W$不一定是唯一的：可能有许多与$W$类似的参数可以正确分类示例。一种看待这个问题的简单的方式是如果$W$的一些参数正确分类了所有样本（对于每个样本来说损失值为0），那么任意倍数的这些参数$\lambda W$（其中$\lambda &gt; 1$）也可以得出损失值为0的结果，因为这种变换均匀地拉伸了所有的得分幅度，以及它们的绝对差异。但是，如果正确分类的和最近的不正确分类的分数差异为15，然后将$W$的所有元素乘以2会使得新的差异值为30。</p><p>换句话说，我们希望对某些权重$W$进行一些偏好编码，以消除这种歧义。我们可以通过用<strong>正则化乘法$R(W)$</strong>来扩展损失函数，做到这一点。最常见的正则化惩罚是<strong>L2</strong>范数，通过对所有参数进行二次方的惩罚来阻止大权重出现：</p><p>$$<br>R(W) = \sum_k\sum_l W_{k,l}^2<br>$$</p><p>在上面的表达式中，我们将$W$中所有元素的平方求和。请注意，正则化函数不是基于数据的函数，它只是基于权重。包括了正则化惩罚在内的完整的多类支持向量机的损失函数由两部分组成：<strong>数据损失</strong>(这是全部样本中平均损失值$L_i$)和<strong>正则化损失</strong>。也就是说，完整的多类SVM损失函数变为以下形式：</p><p><img src="/img/17_08_03/006.png" alt=""></p><p>或者将其扩展为完整形式：</p><p>$$<br>L = \frac{1}{N} \sum_i \sum_{j\neq y_i}<br>\left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] + \lambda \sum_k\sum_l W_{k,l}^2<br>$$</p><p>其中$N$是训练样本的数量。正如你所见的，我们将正则化惩罚附加到损失目标上，由超参数$\lambda$加权。这个超参数通常是由交叉验证来设置，除此之外没有别的简单的方法。</p><p>事实上关于引入正则化惩罚除了上述的动机之外，正则化惩罚还给我们带来了许多理想的性质，其中有许多内容我们将在后面的部分讲到。例如，包括L2惩罚在内的SVM中的<strong>最大间隔</strong>属性（如果你感兴趣的话，见<a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="external">CS229</a>）。</p><p>正则化最具吸引力的功能是可以惩罚大量的权重值使其倾向于增强泛化性能，因此这意味着没有输入数据的情况下也可以通过其自身大幅度的影响评分分值。例如，假设我们有一些输入向量$x = [1,1,1,1]$，以及两个权重向量$w_1 = [1,0,0,0]$，$w_2 = [0.25,0.25,0.25,0.25]$。然后可以得到$w_1^Tx = w_2^Tx = 1$，因此可见两个权重向量得到了相同的结果，但$w_1$的L2惩罚是1.0而$w_2$的L2惩罚仅仅是0.25。因此，根据L2惩罚的结果来看，权重向量$w2$应该被优先选择，因为它实现了较低的正则化损失。从直觉上来看，这是因为$w_2$的权重值更小并且更扩散。由于L2惩罚倾向于更小且更弥散的权重向量，所以最终的分类器更倾向于是将所有的维度都考虑到，而不是一小部分输入维度影响很大。正如我们在稍后的课程中看到的，这种效果可以提高分类器在测试图像上的泛化性能，并防止产生<em>过拟合</em>。</p><p>注意，偏置量具有与权重不同的效果，它不能控制输入数据的影响力。因此，我们通常只对权重$W$进行正则化操作，而不是偏置量$b$。但是，在实践中，这一点通常会忽略不计（即我们统一使用权重和偏置量组合后的矩阵来计算偏差）。最后，请注意，由于正则化惩罚，所以我们绝对不能在所有的样本中的损失值完全为0，除非你错误的把权重矩阵设置为了$W=0$。</p><p><strong>代码.</strong>这是在Python中实现的损失函数（无正则化），这是无向量化以及半向量化的形式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_i</span><span class="params">(x, y, W)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  unvectorized version. Compute the multiclass svm loss for a single example (x,y)</div><div class="line">  - x is a column vector representing an image (e.g. 3073 x 1 in CIFAR-10)</div><div class="line">    with an appended bias dimension in the 3073-rd position (i.e. bias trick)</div><div class="line">  - y is an integer giving index of correct class (e.g. between 0 and 9 in CIFAR-10)</div><div class="line">  - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10)</div><div class="line">  """</div><div class="line">  delta = <span class="number">1.0</span> <span class="comment"># see notes about delta later in this section</span></div><div class="line">  scores = W.dot(x) <span class="comment"># scores becomes of size 10 x 1, the scores for each class</span></div><div class="line">  correct_class_score = scores[y]</div><div class="line">  D = W.shape[<span class="number">0</span>] <span class="comment"># number of classes, e.g. 10</span></div><div class="line">  loss_i = <span class="number">0.0</span></div><div class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> xrange(D): <span class="comment"># iterate over all wrong classes</span></div><div class="line">    <span class="keyword">if</span> j == y:</div><div class="line">      <span class="comment"># skip for the true class to only loop over incorrect classes</span></div><div class="line">      <span class="keyword">continue</span></div><div class="line">    <span class="comment"># accumulate loss for the i-th example</span></div><div class="line">    loss_i += max(<span class="number">0</span>, scores[j] - correct_class_score + delta)</div><div class="line">  <span class="keyword">return</span> loss_i</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_i_vectorized</span><span class="params">(x, y, W)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  A faster half-vectorized implementation. half-vectorized</div><div class="line">  refers to the fact that for a single example the implementation contains</div><div class="line">  no for loops, but there is still one loop over the examples (outside this function)</div><div class="line">  """</div><div class="line">  delta = <span class="number">1.0</span></div><div class="line">  scores = W.dot(x)</div><div class="line">  <span class="comment"># compute the margins for all classes in one vector operation</span></div><div class="line">  margins = np.maximum(<span class="number">0</span>, scores - scores[y] + delta)</div><div class="line">  <span class="comment"># on y-th position scores[y] - scores[y] canceled and gave delta. We want</span></div><div class="line">  <span class="comment"># to ignore the y-th position and only consider margin on max wrong class</span></div><div class="line">  margins[y] = <span class="number">0</span></div><div class="line">  loss_i = np.sum(margins)</div><div class="line">  <span class="keyword">return</span> loss_i</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">L</span><span class="params">(X, y, W)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  fully-vectorized implementation :</div><div class="line">  - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10)</div><div class="line">  - y is array of integers specifying correct class (e.g. 50,000-D array)</div><div class="line">  - W are weights (e.g. 10 x 3073)</div><div class="line">  """</div><div class="line">  <span class="comment"># evaluate loss over all examples in X without using any for loops</span></div><div class="line">  <span class="comment"># left as exercise to reader in the assignment</span></div></pre></td></tr></table></figure><p>这一部分主要介绍了：SVM损失函数采用一种特定的方法来衡量训练数据的预测与实际标签的一致性。此外，对训练集进行良好预测也等同于最大限度地减少损失值。</p><blockquote><p>我们现在要做的是找到一种可以减少损失值的权重的方法。</p></blockquote><h3 id="实际操作中的注意事项"><a href="#实际操作中的注意事项" class="headerlink" title="实际操作中的注意事项"></a>实际操作中的注意事项</h3><p><strong>设置Delta值.</strong>请注意，我们已经学习过超参数$\Delta$以及其设置。那么应该选择设么样的值才是合适的呢？我们是否必须通过交叉验证才能得到呢？事实证明，这个超参数可以在任何情况下被安全的设置为$\Delta = 1.0$。超参数$\Delta$和$\lambda$看起来似乎是两个不同的超参数，但事实上他们控制着相同的操作：都是数据损失和正则化损失直接的权衡。理解这一点的关键是，权重$W$的大小对最终评分有直接影响（这也是他们之间的差异）：当我们缩小$W$的所有数值时，评分的差异将变得更小，反之当我们放大权值$W$时，评分结果的差异也将变大。因此，评分之间的准确的间隔值（例如$\Delta = 1$或者$\Delta = 100$）在某种意义上是无意义的。因为权值可以被任意的缩小或放大。因此，唯一真正的权衡指标是我们允许权值增长的成都（通过正则化强度$\lambda$来控制）。</p><p><strong>与二分类支持向量机的关系.</strong>你可能在参加这个课程之前了解过二分类支持向量机，所以，其中第i个样本的损失可以写成：</p><p>$$<br>L_i = C \max(0, 1 - y_i w^Tx_i) + R(W)<br>$$</p><p>这里的$C$是一个超参数，并且$y_i \in ｛ -1,1 ｝$。你可以尝试自己证明，我们本节所讨论的多类别SVM实际上是包含了二分类SVM这一特例的。也就是说，如果我们只有两个类，那么损失值就降低到上面的二分类SVM损失函数的表达形式。此外，这个表达式中的$C$与之前的$\lambda$对结果起着相同的控制作用，他们之间的关系是：$C \propto \frac{1}{\lambda}$。</p><p><strong>题外话：原始优化.</strong>如果你在此课程之前就已经知道了SVM，那么你可能还听说过SVM的内核，对偶，以及SMO算法等等。在这节课中（与神经网络的情况一样）我们将在无约束的原始形式的情况下优化目标。许多目标在技术上是不可区分的（例如，函数max(x,y)在x=y时无法区分哪一个是大的），但实际上这不是问题，并且常见的是使用子梯形图。</p><p><strong>题外话：其他SVM表达式.</strong>值得注意的是，本节介绍的多类别SVM是在几个多类别SVM中的其中一个。另外一个常用的形式是<em>一对全部One-Vs-All(OVA)</em>SVM，其中每个类别分别对应一个独立的该类别到全部其他类别的二分类SVM。与之相关的一个在实践中不常用到的是<em>全部对全部All-vs-All(AVA)</em>策略。我们的策略是遵循<a href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es1999-461.pdf" target="_blank" rel="external">Weston和Watkins 1999（pdf）</a>的版本，这是一个比OVA更强大的版本（在这个版本的SVM中，您可以构建多类别的数据集，并且实现数据损失为0，但OVA无法做到这一点。如果对此感兴趣，请参阅论文中的细节）。最后一个你可能会见到的表达式是<em>结构化SVM</em>，这最大限度地提高了正确分类的得分与不正确得分中第二高的得分的间隔值的大小。对于这些SVM表达形式的差异的讨论超出了本课程的范畴。这些版本的SVM在实践过程中是可以安全的使用的，但是即使是最简单的OVA策略的形式也可以有效的分类（关于这些讨论，Rikin等人在2004年的<a href="http://www.jmlr.org/papers/volume5/rifkin04a/rifkin04a.pdf" target="_blank" rel="external">In Defense of One-Vs-All Classification (pdf)</a>也有提到）。</p><h3 id="Softmax分类器"><a href="#Softmax分类器" class="headerlink" title="Softmax分类器"></a>Softmax分类器</h3><p>结果表明，SVM是两种常用的分类器之一。另外一个流行的选择是<strong>Softmax分类器</strong>，它拥有与SVM不同的损失函数。如果你之前有听过二分类逻辑回归分类器，那么对于Softmax分类器来说，实际上就是它在多类别上的泛化形式。不同于SVM那样通过函数$f(x_i,W)$为每个类别输出评分（未经校准的评分可能很难定义），Softmax分类器给出了一个稍微更直观的输出（归一化的分类概率），并且还有一个对于概率的解释，我们将在稍后介绍。在Softmax分类器中，映射函数$f(x_i; W) =  W x_i$保持不变，但是我们现在将这些分数解释为每个类的归一化对数概率，并用<strong>交叉熵损失</strong>代替<em>合页损失(hinge loss)</em>：</p><p>$$<br>L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L_i = -f_{y_i} + \log\sum_j e^{f_j}<br>$$</p><p>这里我们使用了符号$f_j$来表示类别分数向量$f$的第j个元素。如上所述，数据集的完全损失是所有训练样本中的$L_i$均值与正则化项$R(W)$所组成。函数$f_j(z) = \frac{e^{z_j}}{\sum_k e^{z_k}}$称为<strong>softmax函数</strong>：它接受一个包含任意真实值的分数向量($z$)，并将其向量值压缩到总和为1的0到1之间的值。如果你是第一次看到涉及softmax功能的完整的交叉熵损失函数，可能会觉得看起来很恐怖，但对于它的功能的理解是相对简单的。</p><p><strong>信息论的观点.</strong>真实分布$p$与假设分布$q$之间的交叉熵定义为：</p><p>$$<br>H(p,q) = - \sum_x p(x) \log q(x)<br>$$</p><p>Softmax分类器最小化了预测分类的概率分布（正如上面所见到的$q = e^{f_{y_i}}  / \sum_j e^{f_j}$）与真实分类的的概率分布的交叉熵，在这里我们指的是所有在正确类别上的概率分布（例如$p = [0, \ldots 1, \ldots, 0]$只包含在$y<em>i$处的一个1）。此外，由于交叉熵可以写作熵和Kullback-Leibler分歧的和的形式：$H(p,q) = H(p) + D</em>{KL}(p||q)$，并且delta函数$p$的熵是0，这也相当于最小化两个分布之间的KL分歧（距离的度量）。换句话说，交叉熵的目标是希望对于正确类别的预测结果的分布与真实分布达到一致。</p><p><strong>概率的解释.</strong>看看下面的表达式：</p><p>$$<br>P(y_i \mid x_i; W) = \frac{e^{f_{y_i}}}{\sum_j e^{f_j} }<br>$$</p><p>这个式子可以解释为对于给定图片$x_i$，并由$W$参数化的分配给正确标签$y_i$的（归一化）概率。为了理解这一点，请回忆一下Softmax分类器将输出向量$f$中的评分值解释为没有归一化的对数概率。那么以这些数值做指数函数的幂就得到了没有归一化的概率，而除法操作则对数据进行了归一化处理，使得这些概率的和为1。从概率论的角度来理解，我们就是在最小化正确分类的负对数概率，这可以看做是在进行<em>最大似然估计</em>（MLE）。该解释的另一个好处是，损失函数中的正则化部分$R(W)$可以被看做是权重矩阵$W$的高斯先验，这里进行的是最大后验估计（MAP）而不是最大似然估计。提及这些解释只是为了让读者形成直观的印象，具体细节就超过本课程范围了。</p><p><strong>实操事项：数值稳定。</strong>编程实现softmax函数计算的时候，中间项$e^{f_{y_i}}$和$\sum_j e^{f_j}$因为存在指数函数，所以数值可能非常大。除以大数值可能导致数值计算的不稳定，所以学会使用归一化技巧非常重要。如果在分式的分子和分母都乘以一个常数C，并把它变换到求和之中，就能得到一个从数学上等价的公式：</p><p>$$<br>\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}<br>= \frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}<br>= \frac{e^{f_{y_i} + \log C}}{\sum_j e^{f_j + \log C}}<br>$$</p><p>$C$的值可自由选择，不会影响计算结果，通过使用这个技巧可以提高计算中的数值稳定性。通常将$C$设为$logC=-max_jf_j$。该技巧简单地说，就是应该将向量$f$中的数值进行平移，使得最大值为0。代码实现如下：</p><h3 id="SVM-vs-Softmax"><a href="#SVM-vs-Softmax" class="headerlink" title="SVM vs Softmax"></a>SVM vs Softmax</h3><h2 id="线性分类的可交互网页演示"><a href="#线性分类的可交互网页演示" class="headerlink" title="线性分类的可交互网页演示"></a>线性分类的可交互网页演示</h2><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2>]]></content:encoded>
      
      <comments>http://studyai.site/2017/08/03/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-2%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/#disqus_thread</comments>
    </item>
    
    <item>
      <title>【斯坦福cs231n】2-1图像分类</title>
      <link>http://studyai.site/2017/07/30/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-1%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</link>
      <guid>http://studyai.site/2017/07/30/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-1%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</guid>
      <pubDate>Sun, 30 Jul 2017 05:27:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;图像分类&quot;&gt;&lt;a href=&quot;#图像分类&quot; class=&quot;headerlink&quot; title=&quot;图像分类&quot;&gt;&lt;/a&gt;图像分类&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;动机.&lt;/strong&gt;在这一部分，我们将介绍图像分类问题，这是将输入图像分配到一组固定类别标签中的某一个标
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h2><p><strong>动机.</strong>在这一部分，我们将介绍图像分类问题，这是将输入图像分配到一组固定类别标签中的某一个标签的任务。尽管这个问题很简单，但它是计算机视觉的核心问题之一，并且有着各种各样的实际应用。此外，正如我们将在后面看到的，许多其它不同的计算机视觉任务（例如对象检测，分割）都可以被简化为图像识别问题。</p><p><strong>示例.</strong>例如，在下面的图像识别的例子中，图像分类模型接收单张图片，并对四个标签{cat，dog，hat，mug}的概率赋值。如图所示，请记住，对于计算机而言，图像被表示为一个大的三维数组。在这个例子中，猫图像是248像素宽，400像素高，并且有三个颜色通道：红色，绿色，蓝色（或简称RGB）。因此，该图像由248 x 400 x 3数字组成，总共297,600个数字。其中每个数字都是一个范围在0（黑色）到255（白色）的整数。我们的任务就是把这将近30万个数字转成像{cat}这样的单一的标签。</p><p><img src="/img/17_07_30/001.png" alt=""></p><blockquote><p>图像分类的任务是预测给定图像的单个标签（或者类似这里的一个标签的概率分布，用于表示我们信心）。图像是包含0到255整数的3维整数，大小是宽度x高度x3。其中3表示RGB三色通道。</p></blockquote><hr><p><strong>挑战.</strong>由于视觉识别问题（例如识别“猫”的例子）对于人类来说，是再简单不过的问题，但从计算机视觉算法的角度来重新审视这个问题，就充满了挑战。在我们下面提出的这些挑战中，请记住图像的原始表示形式为3-D阵列的亮度值：</p><ul><li><strong>不同的观察点(Viewpoint variation)</strong>照相机可以从多个方向来拍摄同一个实例对象。</li><li><strong>大小变化(Scale variation)</strong>视觉分类通常会出现不同的尺寸变化（这里包含在现实世界中的尺寸，不仅仅是针对图像中的大小程度）。</li><li><strong>变形(Deformation)</strong>许多物体并不是刚体，并且可以以极端的方式变形。</li><li><strong>闭塞(Occlusion)</strong>我们所观察的目标对象可能处于被遮挡的状态。有的时候我们只能看到对象的一小部分（像素比较少）。</li><li><strong>光照情况(Illumination conditions)</strong>照明的效果在像素级上的影响是剧烈的。</li><li><strong>背景杂波(Background clutter)</strong>我们所观察的对象可能融入到他们的背景环境中，使其难以识别。</li><li><strong>类型内部变化(Intra-class variation)</strong>我们所关心的类别通常会比较宽泛，比如椅子。不同类型的椅子有着不同的外观，但他们都属于“椅子”这一类别。</li></ul><p>一个好的图片识别分类模型必须在所有这些情况交叉出现的情况下，都能产出不变的结果输出，同时保持类别变化时的敏感性。</p><p><img src="/img/17_07_30/002.jpeg" alt=""></p><hr><p><strong>数据驱动的方法.</strong>如何编写一个将图像分类到不同类别的算法呢？与编写一个像数字排序这样的算法不同的是，如何编写一个识别猫的算法的方法并不是显式的。我们不会视图在代码中指定每个不同的类别在代码中是什么样的，我们所采取的方法就像是在教一个小孩子一样：我们首先为每个类别提供许多个实例，然后开发学习算法，通过学习算法来输入这些类别实例图像，学习到这些每个类别的视觉外观。这种方法被称为数据驱动方法，因为它依赖于事先已经被标记过的标签的图像的训练数据集：</p><p><img src="/img/17_07_30/003.jpg" alt=""></p><blockquote><p>上图是四个视觉类别的训练集示例。在实际情况中，我们可能会有数千种类别和数十万种图像。</p></blockquote><hr><p><strong>图像分类流水线.</strong>正如我们已经看到的，图像分类中的任务是使用一个像素数组来代表一个图像，并且为其分配一个标签。完整的流水线可以表示成如下的流程：</p><ul><li><strong>输入：</strong>我们的输入由一组N个图像组成，每一个都标有K个不同的类别。我们将这些数据称为训练集。</li><li><strong>学习：</strong>我们的任务是使用训练集来了解每一个类别的样子。我们将此步骤称为<em>训练分类器（training a classifier）</em>，或者<em>学习模型（learning a model）</em>。</li><li><strong>评估：</strong>最后，我们通过预测一组从未见过的新图像的标签来评估分类器的质量。然后，我们将这些图像的真实标签与分类器预测的图像进行比较。直观地说，我们希望达到的效果是大多数预测结果与真实答案（我们称之为ground truth）相匹配。</li></ul><h2 id="最邻近分类器（Nearest-Neighbor-Classifier）"><a href="#最邻近分类器（Nearest-Neighbor-Classifier）" class="headerlink" title="最邻近分类器（Nearest Neighbor Classifier）"></a>最邻近分类器（Nearest Neighbor Classifier）</h2><p>我们将开发一种叫做<strong>最邻近分类器</strong>，来作为我们的第一个图片分类的实现。这种分类器与卷积网络无关，在实践中很少使用，但它可以使我们了解处理图像分类问题的基本方法。</p><p><strong>示例图像分类数据集：CIFAR-10.</strong><a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="external">CIFAR-10</a>是一个流行的toy级别的图像分类数据集。这个数据集包含60,000个长宽都是32像素的小图片。每个图片都有一个标签（例如“飞机，汽车，鸟等”）。这60,000张图像被划分为50,000张图像的训练集和10,000张图像的测试集。在下面的图片中，您可以看到10个类别中的每个类别的10个随机示例图像：</p><p><img src="/img/17_07_30/004.jpg" alt=""></p><blockquote><p>左图：来自CIFAR-10数据集的示例图像。右图：第一列显示几个测试图像，并且在每个测试图像旁边，我们根据像素差异显示训练集中的前10个最近邻居。</p></blockquote><hr><p>假设现在我们有50,000张训练图像（50,000张图像都有其对应的标签数据），并且我们希望为剩余的10,000张图片打标签。最邻近分类器将接收一个测试图片，与每一张训练图片做对比，然后以其最接近的训练图像的标签作为其预测标签。在上面的右图中，您可以看到10个示例图片的十个用这种方式得到的最相近的结果图片。请注意，在这10个示例中，有三个图片在检索相同的类别，而其他7个示例并非如此。例如，在第八行最接近“马头图片”的训练的图像是一个“红色汽车图片”，也许是由于它们都拥有黑色背景的原因。这种结果，使得这匹马的形象在这种情况下会被误认为是汽车。</p><p>您可能已经注意到，我们并没有详细的说明我们是如何比较这两个尺寸为32 x 32 x 3的图像的细节的。一种最简单的处理方式是对像素点逐个比较，然后求差值绝对值之和。换句话说，给出两个图像，并将其表示为向量$I_1, I_2$，比较他们的一种合理的方式是求<strong>L1距离</strong>:</p><p>$$<br>d_1 (I_1, I_2) = \sum_p \left| I^p_1 - I^p_2 \right|<br>$$</p><p>下面是将这段程序可视化的过程：</p><p><img src="/img/17_07_30/005.jpeg" alt=""></p><blockquote><p>一个使用L1距离来比较图片像素差异的示例（在这里例子中只有一个颜色通道）。将两个图像元素相减，然后将所有差值相加到一个数字上。如果两个图像相同，则结果将为零。但如果图像非常不同，结果会很大。</p></blockquote><hr><p>我们来看看我们如何在代码中实现分类器。首先，我们将CIFAR-10数据作为4个阵列加载到内存中：用于训练的数据/标签集合，以及用于测试的数据/标签集合。在下面的代码中，<code>Xtr</code>(尺寸是50,000 x 32 x 32 x 3)包含全部的用于训练的图像数据，与之对应的是一个一维数组<code>Ytr</code>(长度是50,000)持有训练集标签(标签是0到9的类别)：</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/') # a magic function we provide</div><div class="line"># flatten out all images to be one-dimensional</div><div class="line">Xtr_rows = Xtr.reshape(Xtr.shape[<span class="number">0</span>], <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>) # Xtr_rows becomes <span class="number">50000</span> x <span class="number">3072</span></div><div class="line">Xte_rows = Xte.reshape(Xte.shape[<span class="number">0</span>], <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>) # Xte_rows becomes <span class="number">10000</span> x <span class="number">3072</span></div></pre></td></tr></table></figure><p>现在我们把所有的图像都拉伸成行了，下面的代码演示了我们如何训练并且评估一个分类器：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="attr">nn</span> = NearestNeighbor() <span class="comment"># create a Nearest Neighbor classifier class</span></div><div class="line">nn.train(Xtr_rows, Ytr) <span class="comment"># train the classifier on the training images and labels</span></div><div class="line"><span class="attr">Yte_predict</span> = nn.predict(Xte_rows) <span class="comment"># predict labels on the test images</span></div><div class="line"><span class="comment"># and now print the classification accuracy, which is the average number</span></div><div class="line"><span class="comment"># of examples that are correctly predicted (i.e. label matches)</span></div><div class="line">print 'accuracy: %f' % ( np.mean(<span class="attr">Yte_predict</span> == Yte) )</div></pre></td></tr></table></figure><p>请注意，作为评估标准，我们通常使用<strong>准确率(accuracy)</strong>来衡量预测结果的准确性。请注意，我们将构建的所有分类器都满足这一个常见的API：它们有一个接受用来学习的数据和标签的<code>train(X,y)</code>函数。在内部，该类应该建立一些标签的模型，以及如何从数据中预测结果的逻辑。同时还需要有一个用来接受新数据并且预测其标签的<code>predict(X)</code>函数。下面是一个L1距离的最邻近分类器的一个简单实现，它满足这套模板：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">NearestNeighbor</span><span class="params">(object)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">pass</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, X, y)</span>:</span></div><div class="line">    <span class="string">""" X is N x D where each row is an example. Y is 1-dimension of size N """</span></div><div class="line">    <span class="comment"># the nearest neighbor classifier simply remembers all the training data</span></div><div class="line">    self.Xtr = X</div><div class="line">    self.ytr = y</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></div><div class="line">    <span class="string">""" X is N x D where each row is an example we wish to predict label for """</span></div><div class="line">    num_test = X.shape[<span class="number">0</span>]</div><div class="line">    <span class="comment"># lets make sure that the output type matches the input type</span></div><div class="line">    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)</div><div class="line"></div><div class="line">    <span class="comment"># loop over all test rows</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</div><div class="line">      <span class="comment"># find the nearest training image to the i'th test image</span></div><div class="line">      <span class="comment"># using the L1 distance (sum of absolute value differences)</span></div><div class="line">      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = <span class="number">1</span>)</div><div class="line">      min_index = np.argmin(distances) <span class="comment"># get the index with smallest distance</span></div><div class="line">      Ypred[i] = self.ytr[min_index] <span class="comment"># predict the label of the nearest example</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> Ypred</div></pre></td></tr></table></figure><p>如果你运行了上面的代码，你将看到这个分类器在CIFAR-10的数据集上只有<strong>38.6%</strong>的准确率。比我们随机选取的结果准确率高一些（随机选取的准确率是10%，因为我们有10个类别），但这个结果与人类真实的识别准确率（估计<a href="http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/" target="_blank" rel="external">约为94%</a>）或者最先进的卷积神经网络能达到的95%准确率相比，差的很远。（见CIFAR-10在Kaggle上的<a href="http://www.kaggle.com/c/cifar-10/leaderboard" target="_blank" rel="external">排行榜</a>）</p><p><strong>距离的选择.</strong>有许多其他的方式来计算两个向量之间的距离。一种比较常用的方式是计算两个向量之间的欧几里得距离，即<strong>L2距离</strong>。公式如下:</p><p>$$<br>d_2 (I_1, I_2) = \sqrt{\sum_{p} \left( I^p_1 - I^p_2 \right)^2}<br>$$</p><p>换句话说，我们之前需要计算两者的像素差，而这一次，我们需要计算像素差的平方，并且把他们加起来之后开根号。在numpy中，我们可以用一行代码来实现上述的计算：</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">distances = <span class="built_in">np</span>.<span class="built_in">sqrt</span>(<span class="built_in">np</span>.<span class="built_in">sum</span>(<span class="built_in">np</span>.square(self.Xtr - X[i,:]), axis = <span class="number">1</span>))</div></pre></td></tr></table></figure><p>请注意，在上面的计算中，我引入了<code>np.sqrt</code>，但在实际的最邻近应用中，我们可以省略求平方根的操作，因为平方根是一个单调函数。也就是说，它对距离的绝对值的差值起到了缩放的作用，但它依然保留了排序结果，因此对于最邻近问题来说，有没有这一步开根号的运算，其结果都是相同的。如果你在CIFAR-10上运行这个L2最邻近分类器，那么你得到的准确率是<strong>35.4%</strong>（比L1的结果略低一些）。</p><p><strong>L1 vs L2.</strong>这两者之间存在什么样的差异呢？这是一个很有意思的问题。在特定的情况下，当涉及两个向量之间的差异时，L2距离比L1距离更糟一些。L1和L2距离（或等效地，一对图像之间的差异的L1 / L2范数）是<a href="http://planetmath.org/vectorpnorm" target="_blank" rel="external">p范数</a>最常用的特殊情况。</p><h3 id="KNN分类器（k-Nearest-Neighbor-Classifier）"><a href="#KNN分类器（k-Nearest-Neighbor-Classifier）" class="headerlink" title="KNN分类器（k - Nearest Neighbor Classifier）"></a>KNN分类器（k - Nearest Neighbor Classifier）</h3><p>您可能已经注意到，当我们想进行预测时，只使用最接近的一个图像的标签是很奇怪的。事实上，通过使用所谓的<strong>KNN分类器</strong>，人们可以做得更好。实际上这个想法很简单：不是在训练集中找到单个最接近的图像，我们将找到最接近的<strong>k</strong>个图像，并让他们对测试图像的标签进行投票。尤其是，当$k=1$的时候，我们KNN分类器实际上就是最邻近分类器。从直觉上来说，较高的<strong>k</strong>值有更平滑的效果，使得分类器更能抵抗离群值：</p><p><img src="/img/17_07_30/006.jpeg" alt=""></p><blockquote><p>上图中，使用二维散点图用三种颜色（红、蓝、绿）来表示三种类别，分别展示了原始数据在最邻近分类器上和在5-NN分类器上的效果。彩色的区域显示在L2距离下生成的<strong>判定边界</strong>。白色区域显示出不能被明确分类的点（即，类别投票至少被分为两类）。请注意，在使用最邻近分类器的情况下，异常值数据点（例如蓝色区域中的绿点）会产生可能不正确的预测的区块，而5-NN分类器在这种情况下会得到相对平滑的效果，这也意味着对测试数据的<strong>泛化</strong>能力更好（未被显示）。还要注意，5-NN图像中的灰色区域是由最邻近的几个邻居颜色不同导致的（例如，有两个是红色的，两个是蓝色的，一个是绿色的）。</p></blockquote><hr><p>在实践中，当我们使用kNN分类器时，应该选择什么样的k值才合适呢？接下来我们来谈谈这个问题。</p><h2 id="验证集，交叉验证，超参数调谐"><a href="#验证集，交叉验证，超参数调谐" class="headerlink" title="验证集，交叉验证，超参数调谐"></a>验证集，交叉验证，超参数调谐</h2><p>kNN分类器需要指定一个k值，但是当k取什么值时效果最好呢？另外，我们还可以选择L1范数、L2范数，等，以及许多我们甚至没有考虑到的选择。这些选择被称为<strong>超参数（Hyperparameter）</strong>，他们在许多机器学习算法的设计过程中都会出现。通常这些值应该被设置为多少，并不是十分显而易见。</p><p>你也许会试图建议我们尝试许多不同的值，然后看看哪些值的效果最好。这的确是一个好办法，这也是我们接下来要做的，但这个过程必须非常仔细地进行。特别要说吗的是，<strong>我们不能使用测试集来调整参数</strong>。当您在设计一款机器学习算法时，您应该将将测试集视为一个非常宝贵的资源，在理想情况下，除非在测试阶段，都不要去触碰它。否则，你调整的参数将会作用域测试集上，这样做非常危险，因为当你开始在真实的数据上使用该模型时，你会发现性能显著降低。在实践过程中，我们称这种现象为<strong>过拟合</strong>测试集。关于这一现象的另一种解释是，如果你在测试集上调整了参数，你实际上是在把测试集当做训练集在使用，因此，你实现的模型的性能对于实际观察到的情况来说都是过于乐观的。但与之相反的，如果我们只是在最后的测试过程中使用一次测试集，那么它仍然是测量分类器<strong>泛化</strong>的一个很好的代理（我们将在以后的课程中看到更多关于泛化的讨论）。</p><blockquote><p>评估测试集在每次训练结束后只运行一次。</p></blockquote><p>幸运的是，有一种不触碰测试集的调整超参数的方法。这个方法就是将我们的训练集分为两部分：其中稍微小一些的那部分训练集，我们称之为<strong>验证集(validation set)</strong>。使用CIFAR-10为例，我们使用49,000的样本作为训练集，然后使用剩下的1,000个样本作为验证集。这个验证集是用来调整超参数的一个假测试集。</p><p>在CIFAR-10中，这个例子看起来可能是这样的：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># assume we have Xtr_rows, Ytr, Xte_rows, Yte as before</span></div><div class="line"><span class="comment"># recall Xtr_rows is 50,000 x 3072 matrix</span></div><div class="line"><span class="attr">Xval_rows</span> = Xtr_rows[:<span class="number">1000</span>, :] <span class="comment"># take first 1000 for validation</span></div><div class="line"><span class="attr">Yval</span> = Ytr[:<span class="number">1000</span>]</div><div class="line"><span class="attr">Xtr_rows</span> = Xtr_rows[<span class="number">1000</span>:, :] <span class="comment"># keep last 49,000 for train</span></div><div class="line"><span class="attr">Ytr</span> = Ytr[<span class="number">1000</span>:]</div><div class="line"></div><div class="line"><span class="comment"># find hyperparameters that work best on the validation set</span></div><div class="line"><span class="attr">validation_accuracies</span> = []</div><div class="line">for k <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]:</div><div class="line">  </div><div class="line">  <span class="comment"># use a particular value of k and evaluation on validation data</span></div><div class="line">  <span class="attr">nn</span> = NearestNeighbor()</div><div class="line">  nn.train(Xtr_rows, Ytr)</div><div class="line">  <span class="comment"># here we assume a modified NearestNeighbor class that can take a k as input</span></div><div class="line">  <span class="attr">Yval_predict</span> = nn.predict(Xval_rows, <span class="attr">k</span> = k)</div><div class="line">  <span class="attr">acc</span> = np.mean(<span class="attr">Yval_predict</span> == Yval)</div><div class="line">  print 'accuracy: %f' % (acc,)</div><div class="line"></div><div class="line">  <span class="comment"># keep track of what works on the validation set</span></div><div class="line">  validation_accuracies.append((k, acc))</div></pre></td></tr></table></figure><p>在此过程结束之前，我们可以绘制一个图表，来显示哪个k值表现的更好。然后我们使用这个最好的k值，对真正的测试集进行一次评估。</p><blockquote><p>将你的训练集分割为训练集和验证集。使用验证集来调整所有的超参数。最后在测试集上仅运行一次评估操作，并上报结果。</p></blockquote><p><strong>交叉验证.</strong>在你的训练集（同时也包括验证集）可能非常小的情况下，人们有时使用一个更复杂叫做<strong>交叉验证</strong>的技术来调节超参数。作用于我们之前的例子中，取代之前我们选取1000个数据点来作为验证集、剩下的部分用做测试集这种方式，我们通过迭代不同的验证集以及求得他们的平均表现这种方式，来得到一个更好的，噪音更小的k值。举个例子，在5倍交叉验证中，我们将数据分为5等份，使用其中4份来训练，用剩余的1份作为验证。然后我们迭代所有其他份数据来作为验证集，计算每一份作为验证集的最终表现，最终将每次得到的表现求和在求平均值。</p><p><img src="/img/17_07_30/007.png" alt=""></p><blockquote><p>参数k的五倍交叉验证运行示例。对于k的每个值，我们都在4份数据上训练，并且在第5份数据上评估。因此，对于每个k，我们在交叉验证上都会有5个评估得到的准确率（y轴是准确率，每个结果对应一个点）。趋势曲线通过每个k的结果的平均值绘制，错误条表明标准偏差。注意在这里的一个特定场景，交叉验证集建议我们选取的k=7，此时在数据集上的预测效果最好（对应于图中的峰值处）。如果我们使用超过5份的数据，我们也许会看到一个更平滑（低噪音）的曲线。</p></blockquote><hr><p><strong>实践.</strong>在实践中，人们更倾向于避免使用交叉验证，人们更愿意接受单个的验证集分割，因为交叉验证的计算是十分昂贵的。人们倾向使用的分割方式是将训练集分割50%-90%用作训练，剩下的部分用作验证。然而，这取决于多个因素：例如如果超参数数量很大，你也许更倾向于使用一个更大的验证集分割。如果验证集样本的数量很少（可能只有几百个），那么使用交叉验证则更安全一些。正如你所见的，典型的交叉验证可能会是三等分、5等分或者10等分的交叉验证。</p><p><img src="/img/17_07_30/008.jpeg" alt=""></p><blockquote><p>常见的数据分割。给定训练集和测试集。训练集被分割为几等份（例如这里的五等分）。第1-4份数据作为训练集。一份作为验证集（例如这里的黄颜色的第五份），用来调节超参数。交叉验证更进一步的操作是迭代循环这5份数据，分别作为验证集的预测结果。这被称为5倍交叉验证。一旦模型被训练，并且确定了所有的最佳的超参数，最终在测试集（红色）上单词评估干模型。</p></blockquote><hr><h2 id="最近邻分类器的优缺点"><a href="#最近邻分类器的优缺点" class="headerlink" title="最近邻分类器的优缺点"></a>最近邻分类器的优缺点</h2><p>思考最邻近分类器的优缺点是一件值得做的事情。很明显，一个优点是：它的实现很简单，理解起来也很简单。此外，这个分类器不需要训练的时间，因为用于预测结果的数据全部来自于被存储的以及可能被索引的训练数据。但是，我们需要消耗一次测试的时间，因为对测试数据进行分类，我们需要将每个训练样本进行比较。这是一种不好的方式，因为在实践过程中，我们往往很在意测试运行的时间，而不太在意训练所花费的时间。事实上，我们将在稍后的深度神经网络课程中，我们将看到另一个极端：它会在训练样本的过程中花费巨大的开销，但一旦训练结束，在一个新的测试样本上执行分类任务时的开销是非常小的。这种模式在实践中更为理想。</p><p>除此之外，关于最邻近分类器的计算复杂度问题，一直是一个活跃的研究领域，并且有一些可以加速数据集中最邻近数据的查找的<strong>近似最邻近（Approximate Nearest Neighbor(ANN)）</strong>算法和库存在（例如<a href="http://www.cs.ubc.ca/research/flann/" target="_blank" rel="external">FLANN</a>）。这些算法允许在检索期间以其空间/时间复杂度来折衷最近相邻检索的正确性，并且通常依赖于涉及构建kdtree或运行k-means算法的预处理/索引阶段。</p><p>在某些场景中，最近邻分类器有时可能是一个很好的选择（特别是如果数据是低维数据），但很少适用于实际的图像分类场景。其中一个问题是图像是高维度对象（即它们通常包含许多像素），并且高维空间的距离是非常不直观的。下面的图像说明了我们上面开发的基于像素的L2相似度与人类感知相似性的区别：</p><p><img src="/img/17_07_30/009.png" alt=""></p><blockquote><p>高维数据（尤其是图像）上基于像素的距离可能非常不直观。基于L2像素距离，原始图像（左）和旁边的三个其他图像都距离它们相同。显然，像素方向的距离并不能与人类感知上的相似性相对应。</p></blockquote><hr><p>这里有更多的可视化数据来说服你，使用像素差异来比较图像是不够的。我们可以使用一种名为t-SNE的可视化技术来拍摄CIFAR-10图像，并将其嵌入到二维空间中，使其（局部）成对距离最好地保留下来。在这种可视化中，根据我们上面开发的L2像素距离，我们将其L2距离相对较小的图像聚集在一起：</p><p><img src="/img/17_07_30/010.jpg" alt=""></p><blockquote><p>使用t-SNE嵌入二维的CIFAR-10图像。该图像附近的图像被认为是基于L2像素距离接近的。注意到背景的强烈影响，而不是语义层次的差异。点击<a href="http://cs231n.github.io/assets/pixels_embed_cifar10_big.jpg" target="_blank" rel="external">这里</a>查看这个可视化的更大版本。</p></blockquote><hr><p>特别地，请注意，彼此相邻的图像更多是图像的平均颜色分布或背景的类型相似的图像，而不是其相似的标签类型的图像。例如，可以看到一张狗的图片和一张青蛙的照片像邻，因为两者都是在白色背景上。理想情况下，我们希望所有10个类中的图像形成自己的集群，使得同一类的图像在彼此附近，而不管不相关的特征和变化（如背景）。然而，要获得这个属性，我们将不得不超越像素级别的去考虑问题。</p><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>综上所述：</p><ul><li>我们引入了<strong>图像分类</strong>的问题，其中给出了一组全部标记为单一类别的图像。然后，我们要求为这些类别预测一组新的测试图像，并测量预测的准确性。</li><li>我们引入了一个称为<strong>最近邻分类器</strong>的简单分类<strong>器</strong>。我们看到有与此分类器相关联的多个超参数（如k值或用于比较示例的距离类型），并没有明显的选择方式。</li><li>我们看到设置这些超参数的正确方法是将训练数据分为两个：训练集和假测试集，我们称之为<strong>验证集</strong>。我们尝试不同的超参数值，并保持在验证集上达到最佳性能的值。</li><li>如果缺乏培训数据是一个问题，我们讨论了一个称为<strong>交叉验证</strong>的过程，它可以帮助减少噪声，以估计哪些超参数最有效。</li><li>一旦找到了最佳的超参数，我们修复它们，并对实际测试集执行单个<strong>评估</strong>。</li><li>我们看到最近邻居可以在CIFAR-10上获得约40％的准确性。它实现起来很简单，但要求我们存储整个训练集，并且在测试图像上进行评估是很昂贵的。</li><li>最后，我们看到在原始像素值上使用L1或L2距离是不够的，因为这些距离与图像的背景和颜色分布相比，与其语义内容相比更强烈。</li></ul><p>在接下来的课程中，我们将着手解决这些挑战，最终达成90％精度的解决方案，让我们在完成学习后完全丢弃训练集，并允许我们在不到一毫秒内评估测试图像。</p><h2 id="总结：在实践中应用kNN"><a href="#总结：在实践中应用kNN" class="headerlink" title="总结：在实践中应用kNN"></a>总结：在实践中应用kNN</h2><p>如果您希望在实践中应用kNN（希望不是在图像上），请按如下步骤进行：</p><ul><li>1.预处理数据：规范数据中的特征（例如图像中的一个像素），使其具有零均值和单位方差。我们将在后面的章节中更详细地介绍这一点，并且选择不覆盖本节中的数据规范化，因为图像中的像素通常是均匀的，并且不会展现出广泛不同的分布，从而减轻了数据规范化的需要。</li><li>2.如果您的数据非常高，请考虑使用维度降低技术，如PCA（<a href="http://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="external">wiki ref</a>，<a href="http://cs229.stanford.edu/notes/cs229-notes10.pdf" target="_blank" rel="external">CS229ref</a>，<a href="http://www.bigdataexaminer.com/cgi-sys/suspendedpage.cgi" target="_blank" rel="external">博客引用</a>），甚至使用<a href="http://scikit-learn.org/stable/modules/random_projection.html" target="_blank" rel="external">随机投影</a>。</li><li>3.将您的训练数据随机分成训练集/验证集。根据经验，70-90％的数据通常会分配到训练集上。此设置取决于您拥有多少超参数以及您期望他们拥有多少影响力。如果有很多超参数需要估计，那么您应该在验证集更大的一边进行有效的估计。如果您的验证数据集比较小，最好将训练数据拆分为几等分，并执行交叉验证。如果你能负担得起计算机的运算量，那么交叉验证（更多的份数越好，但是更昂贵）总是更安全。</li><li>4.对于k的许多选择（比如越多越好）和不同距离类型（L1和L2都是不错的选择），对验证数集（对于所有份数，如果进行交叉验证）训练和评估kNN分类器。</li><li>5.如果您的kNN分类器运行时间过长，请考虑使用近似最近邻库（<a href="http://www.cs.ubc.ca/research/flann/" target="_blank" rel="external">FLANN</a>）来加速检索（以某种精度为代价）。</li><li>6.记下提供最佳效果的超参数。有一个问题是您应该使用最佳超参数的完整训练集，因为如果要将验证数据折叠到训练集中（因为数据的大小会更大），最佳超参数可能会改变。实际上，在最终分类器中不使用验证数据更为清晰，并且在估计超参数时认为它被刻录。评估测试集上的最佳模型。上报在测试集上的准确率，这个结果作为kNN分类器的最终表现。</li></ul><h2 id="进一步阅读"><a href="#进一步阅读" class="headerlink" title="进一步阅读"></a>进一步阅读</h2><p>这里有一些（可选）链接，您可能会发现更多有趣的东西：</p><ul><li><a href="http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf" target="_blank" rel="external">关于机器学习的一些有用的事情</a>，其中特别是第6部分是相关的，但这整篇文章都是值得一读的。</li><li><a href="http://people.csail.mit.edu/torralba/shortCourseRLOC/index.html" target="_blank" rel="external">认可和学习对象类别</a>，ICCV 2005的短期课程对象分类。</li></ul>]]></content:encoded>
      
      <comments>http://studyai.site/2017/07/30/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-1%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
